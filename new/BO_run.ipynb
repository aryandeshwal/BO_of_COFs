{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-performer",
   "metadata": {},
   "source": [
    "# BO runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "municipal-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/cokes/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/cokes/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/cokes/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/cokes/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/cokes/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/cokes/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/cokes/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/cokes/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from botorch.models import FixedNoiseGP, SingleTaskGP\n",
    "from gpytorch.kernels import ScaleKernel\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rapid-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_acquisition = \"EI\"\n",
    "# which_acquisition = \"max y_hat\"\n",
    "# which_acquisition = \"max sigma\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-internet",
   "metadata": {},
   "source": [
    "load data from `prepare_Xy.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perfect-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69839"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pickle.load(open('inputs_and_outputs.pkl', 'rb'))['X']\n",
    "y = pickle.load(open('inputs_and_outputs.pkl', 'rb'))['y']\n",
    "y = np.reshape(y, (np.size(y), 1)) # for the GP\n",
    "nb_data = np.size(y)\n",
    "nb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-juice",
   "metadata": {},
   "source": [
    "convert to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arabic-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worldwide-brand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([69839, 12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sexual-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([69839, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instant-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unsqueezed = X.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fancy-catalyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69839"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-nightlife",
   "metadata": {},
   "source": [
    "number of COFs for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "professional-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_COFs_initialization = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unlimited-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_run(nb_iterations, verbose=False):\n",
    "    assert nb_iterations > nb_COFs_initialization\n",
    "    \n",
    "    # select initial COFs for training data randomly.\n",
    "    # idea is to keep populating this ids_acquired and return it for analysis.\n",
    "    ids_acquired = np.random.choice(np.arange((nb_data)), size=nb_COFs_initialization, replace=False)\n",
    "\n",
    "    # initialize acquired y, since it requires normalization\n",
    "    y_acquired = y[ids_acquired]\n",
    "    # standardize outputs\n",
    "    y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)\n",
    "    \n",
    "    for i in range(nb_COFs_initialization, nb_iterations):\n",
    "        print(\"iteration:\", i, end=\"\\r\")\n",
    "        # construct and fit GP model\n",
    "        model = SingleTaskGP(X[ids_acquired, :], y_acquired)\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_model(mll)\n",
    "\n",
    "        # set up acquisition function\n",
    "        if which_acquisition == \"EI\":\n",
    "            acquisition_function = ExpectedImprovement(model, best_f=y_acquired.max().item())\n",
    "            \n",
    "            # compute aquisition function at each COF in the database. \n",
    "#             batch_size = 35000 # need to do in batches to avoid mem issues\n",
    "#             acquisition_values = torch.zeros((nb_data))\n",
    "#             acquisition_values[:] = np.NaN # for safety\n",
    "#             nb_batches = nb_data // batch_size\n",
    "#             for ba in range(nb_batches+1):\n",
    "#                 id_start = ba * batch_size\n",
    "#                 id_end   = id_start + batch_size\n",
    "#                 if id_end > nb_data:\n",
    "#                     id_end = nb_data\n",
    "#                 with torch.no_grad():\n",
    "#                     acquisition_values[id_start:id_end] = acquisition_function.forward(X_unsqueezed[id_start:id_end])\n",
    "#             assert acquisition_values.isnan().sum().item() == 0 # so that all are filled properly.\n",
    "            with torch.no_grad(): # to avoid memory issues; we arent using the gradient...\n",
    "                acquisition_values = acquisition_function.forward(X_unsqueezed) # runs out of memory\n",
    "        elif which_acquisition == \"max y_hat\":\n",
    "            with torch.no_grad():\n",
    "                acquisition_values = model.posterior(X_unsqueezed).mean.squeeze()\n",
    "        elif which_acquisition == \"max sigma\":\n",
    "            with torch.no_grad():\n",
    "                acquisition_values = model.posterior(X_unsqueezed).variance.squeeze()\n",
    "        else:\n",
    "            raise Exception(\"not a valid acquisition function\")\n",
    "\n",
    "        # select COF to acquire with maximal aquisition value, which is not in the acquired set already\n",
    "        ids_sorted_by_aquisition = acquisition_values.argsort(descending=True)\n",
    "        for id_max_aquisition_all in ids_sorted_by_aquisition:\n",
    "            if not id_max_aquisition_all.item() in ids_acquired:\n",
    "                id_max_aquisition = id_max_aquisition_all.item()\n",
    "                break\n",
    "\n",
    "        # acquire this COF\n",
    "        ids_acquired = np.concatenate((ids_acquired, [id_max_aquisition]))\n",
    "        assert np.size(ids_acquired) == i + 1\n",
    "\n",
    "        # update y aquired; start over to normalize properly\n",
    "        y_acquired = y[ids_acquired, :] # start over to normalize y properly\n",
    "        y_acquired = (y_acquired - torch.mean(y_acquired)) / torch.std(y_acquired)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\tacquired COF\", id_max_aquisition, \"with y = \", y[id_max_aquisition].item())\n",
    "            print(\"\\tbest y acquired:\", y[ids_acquired].max().item())\n",
    "        \n",
    "    assert np.size(ids_acquired) == nb_iterations\n",
    "    return ids_acquired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-biography",
   "metadata": {},
   "source": [
    "`ids_acquired[r, i]` will give ID of COF acquired during iteration `i` from run `r`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frank-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RUN 0\n",
      "took time t =  7.237610721588135 min\n",
      "\n",
      "\n",
      "RUN 1\n",
      "took time t =  7.30598794221878 min\n",
      "\n",
      "\n",
      "RUN 2\n",
      "took time t =  7.276894311110179 min\n",
      "\n",
      "\n",
      "RUN 3\n",
      "took time t =  7.1658613920211796 min\n",
      "\n",
      "\n",
      "RUN 4\n",
      "took time t =  7.263525919119517 min\n",
      "\n",
      "\n",
      "RUN 5\n",
      "took time t =  7.240882853666942 min\n",
      "\n",
      "\n",
      "RUN 6\n",
      "took time t =  7.337699552377065 min\n",
      "\n",
      "\n",
      "RUN 7\n",
      "took time t =  7.284728991985321 min\n",
      "\n",
      "\n",
      "RUN 8\n",
      "took time t =  7.325448171297709 min\n",
      "\n",
      "\n",
      "RUN 9\n",
      "took time t =  7.570803308486939 min\n",
      "\n",
      "\n",
      "RUN 10\n",
      "took time t =  7.266802322864533 min\n",
      "\n",
      "\n",
      "RUN 11\n",
      "took time t =  7.262774999936422 min\n",
      "\n",
      "\n",
      "RUN 12\n",
      "took time t =  7.127003467082977 min\n",
      "\n",
      "\n",
      "RUN 13\n",
      "took time t =  7.364107779661814 min\n",
      "\n",
      "\n",
      "RUN 14\n",
      "took time t =  7.3784677942593895 min\n",
      "\n",
      "\n",
      "RUN 15\n",
      "took time t =  7.253569904963175 min\n",
      "\n",
      "\n",
      "RUN 16\n",
      "took time t =  7.307559335231781 min\n",
      "\n",
      "\n",
      "RUN 17\n",
      "took time t =  7.451583731174469 min\n",
      "\n",
      "\n",
      "RUN 18\n",
      "took time t =  7.553135732809703 min\n",
      "\n",
      "\n",
      "RUN 19\n",
      "took time t =  7.296091318130493 min\n",
      "\n",
      "\n",
      "RUN 20\n",
      "took time t =  7.2720548470815025 min\n",
      "\n",
      "\n",
      "RUN 21\n",
      "took time t =  7.0214725454648335 min\n",
      "\n",
      "\n",
      "RUN 22\n",
      "took time t =  7.253600736459096 min\n",
      "\n",
      "\n",
      "RUN 23\n",
      "took time t =  7.4795437216758724 min\n",
      "\n",
      "\n",
      "RUN 24\n",
      "took time t =  7.397281940778097 min\n",
      "\n",
      "\n",
      "RUN 25\n",
      "took time t =  7.274005671342214 min\n",
      "\n",
      "\n",
      "RUN 26\n",
      "took time t =  7.134894414742788 min\n",
      "\n",
      "\n",
      "RUN 27\n",
      "took time t =  7.2170882741610205 min\n",
      "\n",
      "\n",
      "RUN 28\n",
      "iteration: 78\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cokes/.local/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py:263: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  NumericalWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took time t =  7.055034768581391 min\n",
      "\n",
      "\n",
      "RUN 29\n",
      "took time t =  7.425979002316793 min\n",
      "\n",
      "\n",
      "RUN 30\n",
      "took time t =  7.601202404499054 min\n",
      "\n",
      "\n",
      "RUN 31\n",
      "took time t =  7.254582150777181 min\n",
      "\n",
      "\n",
      "RUN 32\n",
      "took time t =  7.32819838921229 min\n",
      "\n",
      "\n",
      "RUN 33\n",
      "took time t =  7.508639041582743 min\n",
      "\n",
      "\n",
      "RUN 34\n",
      "took time t =  7.175657308101654 min\n",
      "\n",
      "\n",
      "RUN 35\n",
      "took time t =  7.168862398465475 min\n",
      "\n",
      "\n",
      "RUN 36\n",
      "took time t =  7.118225149313608 min\n",
      "\n",
      "\n",
      "RUN 37\n",
      "took time t =  7.218559682369232 min\n",
      "\n",
      "\n",
      "RUN 38\n",
      "took time t =  7.178347424666087 min\n",
      "\n",
      "\n",
      "RUN 39\n",
      "took time t =  7.149571132659912 min\n",
      "\n",
      "\n",
      "RUN 40\n",
      "took time t =  7.397369893391927 min\n",
      "\n",
      "\n",
      "RUN 41\n",
      "took time t =  7.374075202147166 min\n",
      "\n",
      "\n",
      "RUN 42\n",
      "took time t =  7.3341242591540015 min\n",
      "\n",
      "\n",
      "RUN 43\n",
      "took time t =  7.261066178480784 min\n",
      "\n",
      "\n",
      "RUN 44\n",
      "took time t =  7.141440697511038 min\n",
      "\n",
      "\n",
      "RUN 45\n",
      "took time t =  7.313784658908844 min\n",
      "\n",
      "\n",
      "RUN 46\n",
      "took time t =  7.267547098795573 min\n",
      "\n",
      "\n",
      "RUN 47\n",
      "took time t =  7.20398888985316 min\n",
      "\n",
      "\n",
      "RUN 48\n",
      "took time t =  7.437757857640585 min\n",
      "\n",
      "\n",
      "RUN 49\n",
      "took time t =  7.218947410583496 min\n",
      "\n",
      "\n",
      "RUN 50\n",
      "took time t =  7.493029769261678 min\n",
      "\n",
      "\n",
      "RUN 51\n",
      "took time t =  7.450812164942423 min\n",
      "\n",
      "\n",
      "RUN 52\n",
      "took time t =  7.184896246592204 min\n",
      "\n",
      "\n",
      "RUN 53\n",
      "took time t =  7.236911598841349 min\n",
      "\n",
      "\n",
      "RUN 54\n",
      "took time t =  7.327038383483886 min\n",
      "\n",
      "\n",
      "RUN 55\n",
      "took time t =  7.282283405462901 min\n",
      "\n",
      "\n",
      "RUN 56\n",
      "took time t =  7.380854411919912 min\n",
      "\n",
      "\n",
      "RUN 57\n",
      "took time t =  7.353207222620646 min\n",
      "\n",
      "\n",
      "RUN 58\n",
      "took time t =  7.448291130860647 min\n",
      "\n",
      "\n",
      "RUN 59\n",
      "took time t =  7.5363772710164385 min\n",
      "\n",
      "\n",
      "RUN 60\n",
      "took time t =  7.202328856786092 min\n",
      "\n",
      "\n",
      "RUN 61\n",
      "took time t =  7.447040545940399 min\n",
      "\n",
      "\n",
      "RUN 62\n",
      "took time t =  7.211400802930196 min\n",
      "\n",
      "\n",
      "RUN 63\n",
      "took time t =  7.560369396209717 min\n",
      "\n",
      "\n",
      "RUN 64\n",
      "took time t =  7.230643598238627 min\n",
      "\n",
      "\n",
      "RUN 65\n",
      "took time t =  7.261888154347738 min\n",
      "\n",
      "\n",
      "RUN 66\n",
      "took time t =  7.355716152985891 min\n",
      "\n",
      "\n",
      "RUN 67\n",
      "took time t =  7.425435543060303 min\n",
      "\n",
      "\n",
      "RUN 68\n",
      "took time t =  7.367885267734527 min\n",
      "\n",
      "\n",
      "RUN 69\n",
      "took time t =  7.487645892302195 min\n",
      "\n",
      "\n",
      "RUN 70\n",
      "took time t =  7.497790106137594 min\n",
      "\n",
      "\n",
      "RUN 71\n",
      "took time t =  7.336937848726908 min\n",
      "\n",
      "\n",
      "RUN 72\n",
      "took time t =  7.299442613124848 min\n",
      "\n",
      "\n",
      "RUN 73\n",
      "took time t =  7.724779530366262 min\n",
      "\n",
      "\n",
      "RUN 74\n",
      "took time t =  7.473151163260142 min\n",
      "\n",
      "\n",
      "RUN 75\n",
      "took time t =  7.4461992104848225 min\n",
      "\n",
      "\n",
      "RUN 76\n",
      "took time t =  7.6278742750485735 min\n",
      "\n",
      "\n",
      "RUN 77\n",
      "took time t =  7.1177510023117065 min\n",
      "\n",
      "\n",
      "RUN 78\n",
      "took time t =  7.31965833902359 min\n",
      "\n",
      "\n",
      "RUN 79\n",
      "took time t =  7.430999302864075 min\n",
      "\n",
      "\n",
      "RUN 80\n",
      "took time t =  7.2871841311454775 min\n",
      "\n",
      "\n",
      "RUN 81\n",
      "iteration: 82\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cokes/.local/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py:263: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-10.\n",
      "  NumericalWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took time t =  7.436510316530863 min\n",
      "\n",
      "\n",
      "RUN 82\n",
      "took time t =  7.304804150263468 min\n",
      "\n",
      "\n",
      "RUN 83\n",
      "took time t =  7.327514203389486 min\n",
      "\n",
      "\n",
      "RUN 84\n",
      "took time t =  7.376877991358439 min\n",
      "\n",
      "\n",
      "RUN 85\n",
      "took time t =  7.5617250045140585 min\n",
      "\n",
      "\n",
      "RUN 86\n",
      "took time t =  7.26043134133021 min\n",
      "\n",
      "\n",
      "RUN 87\n",
      "took time t =  7.4054002404212955 min\n",
      "\n",
      "\n",
      "RUN 88\n",
      "took time t =  7.160198378562927 min\n",
      "\n",
      "\n",
      "RUN 89\n",
      "took time t =  7.317469696203868 min\n",
      "\n",
      "\n",
      "RUN 90\n",
      "took time t =  7.337529293696085 min\n",
      "\n",
      "\n",
      "RUN 91\n",
      "took time t =  7.506365013122559 min\n",
      "\n",
      "\n",
      "RUN 92\n",
      "took time t =  7.476064924399058 min\n",
      "\n",
      "\n",
      "RUN 93\n",
      "took time t =  7.318663656711578 min\n",
      "\n",
      "\n",
      "RUN 94\n",
      "took time t =  7.3077609499295555 min\n",
      "\n",
      "\n",
      "RUN 95\n",
      "took time t =  8.31069944302241 min\n",
      "\n",
      "\n",
      "RUN 96\n",
      "took time t =  7.400353403886159 min\n",
      "\n",
      "\n",
      "RUN 97\n",
      "took time t =  7.146096642812093 min\n",
      "\n",
      "\n",
      "RUN 98\n",
      "took time t =  7.348718508084615 min\n",
      "\n",
      "\n",
      "RUN 99\n",
      "took time t =  7.142310913403829 min\n"
     ]
    }
   ],
   "source": [
    "bo_res = dict()\n",
    "bo_res['nb_runs']       = 100\n",
    "bo_res['nb_iterations'] = 250\n",
    "bo_res['ids_acquired'] = []\n",
    "for r in range(bo_res['nb_runs']):\n",
    "    print(\"\\n\\nRUN\", r)\n",
    "    t0 = time.time()\n",
    "    ids_acquired = bo_run(bo_res['nb_iterations'])\n",
    "    bo_res['ids_acquired'].append(ids_acquired)\n",
    "    print(\"took time t = \", (time.time() - t0) / 60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "congressional-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bo_results' + which_acquisition + '.pkl', 'wb') as file:\n",
    "    pickle.dump(bo_res, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-intermediate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
